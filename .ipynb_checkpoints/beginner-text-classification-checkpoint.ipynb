{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "#importing modules\n",
    "import pandas as pd# data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "X = [] # an element of X is represented as (filename,text)\n",
    "Y = [] # an element of Y represents the newsgroup category of the corresponding X element\n",
    "ls=listdir('C:/Users/HP/Downloads/coding_ninja_docs/text classification/20_newsgroups/20_newsgroups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in ls:\n",
    "    folder=listdir('C:/Users/HP/Downloads/coding_ninja_docs/text classification/20_newsgroups/20_newsgroups/'+category)\n",
    "    for document in folder:\n",
    "        with open('C:/Users/HP/Downloads/coding_ninja_docs/text classification/20_newsgroups/20_newsgroups/'+category+'/'+document, \"r\",encoding=\"ISO-8859-1\") as f:\n",
    "            X.append((document,f.read()))\n",
    "            Y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a list of common words to be removed next \n",
    "#without effecting the prediction result\n",
    "stopwords = ['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone',\n",
    "             'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount',\n",
    "             'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around',\n",
    "             'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before',\n",
    "             'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both',\n",
    "             'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'con', 'could', 'couldnt', 'cry', 'de',\n",
    "             'describe', 'detail', 'did', 'do', 'does', 'doing', 'don', 'done', 'down', 'due', 'during', 'each', 'eg',\n",
    "             'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone',\n",
    "             'everything', 'everywhere', 'except', 'few', 'fifteen', 'fify', 'fill', 'find', 'fire', 'first', 'five', 'for',\n",
    "             'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had',\n",
    "             'has', 'hasnt', 'have', 'having', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed',\n",
    "             'interest', 'into', 'is', 'it', 'its', 'itself', 'just', 'keep', 'last', 'latter', 'latterly', 'least', 'less',\n",
    "             'ltd', 'made', 'many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly',\n",
    "             'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine',\n",
    "             'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'once',\n",
    "             'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own',\n",
    "             'part', 'per', 'perhaps', 'please', 'put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed', 'seeming',\n",
    "             'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'so', \n",
    "             'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system',\n",
    "             't', 'take', 'ten', 'than', 'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there',\n",
    "             'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thickv', 'thin', 'third', 'this',\n",
    "             'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward',\n",
    "             'towards', 'twelve', 'twenty', 'two', 'un', 'under', 'until', 'up', 'upon', 'us', 'very', 'via', 'was', 'we',\n",
    "             'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby',\n",
    "             'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom',\n",
    "             'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself',\n",
    "             'yourselves']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "for i in range(len(X_train)):\n",
    "    word_list = []\n",
    "    for word in X_train[i][1].split():\n",
    "        word_new  = word.strip(string.punctuation).lower()\n",
    "        if (len(word_new)>2)  and (word_new not in stopwords):  \n",
    "            if word_new in vocab:\n",
    "                vocab[word_new]+=1\n",
    "            else:\n",
    "                vocab[word_new]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_words = [0 for i in range(max(vocab.values())+1)] \n",
    "freq = [i for i in range(max(vocab.values())+1)] \n",
    "for key in vocab:\n",
    "    num_words[vocab[key]]+=1\n",
    "    \n",
    "plt.axis([0, 10, 0, 20000])\n",
    "plt.bar(freq,num_words,color='maroon',width = 0.4)\n",
    "plt.xlabel(\"Frequency\",fontsize=12)\n",
    "plt.ylabel(\"No of words\",fontsize=12)\n",
    "plt.title(\"No of words Vs Frequency\",fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words with higher frequency than cutoff frequency(50) : 5938\n"
     ]
    }
   ],
   "source": [
    "# deciding cutoff frequency\n",
    "cutoff_freq= 50\n",
    "num_words_above_cutoff = len(vocab)-sum(num_words[0:cutoff_freq]) \n",
    "print(\"Number of words with higher frequency than cutoff frequency({}) :\".format(cutoff_freq),num_words_above_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list named \"feature\" with these above words and removing words with less frequency than cut off  \n",
    "features = []\n",
    "for key in vocab:\n",
    "    if vocab[key] >=cutoff_freq:\n",
    "        features.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# representing training data as word vector counts\n",
    "X_train_dataset = np.zeros((len(X_train),len(features)))\n",
    "# It'll actually take some time to complete\n",
    "for i in range(len(X_train)):\n",
    "    #print(i)\n",
    "    word_list = [ word.strip(string.punctuation).lower() for word in X_train[i][1].split()]\n",
    "    for word in word_list:\n",
    "        if word in features:\n",
    "            X_train_dataset[i][features.index(word)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the same w/ testing data and it's again going to take lots of time\n",
    "X_test_dataset = np.zeros((len(X_test),len(features)))\n",
    "for i in range(len(X_test)):\n",
    "    word_list = [ word.strip(string.punctuation).lower() for word in X_test[i][1].split()]\n",
    "    for word in word_list:\n",
    "        if word in features:\n",
    "            X_test_dataset[i][features.index(word)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Multinomial Naive Bayes from Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn's score on training data : 0.9184503567380142\n",
      "Sklearn's score on testing data : 0.8718\n",
      "Classification report for testing data :-\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.75      0.81      0.78       233\n",
      "           comp.graphics       0.80      0.83      0.81       253\n",
      " comp.os.ms-windows.misc       0.82      0.83      0.83       249\n",
      "comp.sys.ibm.pc.hardware       0.82      0.88      0.85       240\n",
      "   comp.sys.mac.hardware       0.88      0.93      0.90       236\n",
      "          comp.windows.x       0.92      0.86      0.89       240\n",
      "            misc.forsale       0.81      0.86      0.83       261\n",
      "               rec.autos       0.92      0.93      0.92       269\n",
      "         rec.motorcycles       0.93      0.97      0.95       284\n",
      "      rec.sport.baseball       0.99      0.97      0.98       248\n",
      "        rec.sport.hockey       0.98      0.98      0.98       231\n",
      "               sci.crypt       0.96      0.90      0.93       233\n",
      "         sci.electronics       0.89      0.87      0.88       244\n",
      "                 sci.med       0.95      0.91      0.93       256\n",
      "               sci.space       0.94      0.93      0.93       246\n",
      "  soc.religion.christian       0.94      0.98      0.96       252\n",
      "      talk.politics.guns       0.77      0.89      0.83       249\n",
      "   talk.politics.mideast       0.93      0.90      0.92       281\n",
      "      talk.politics.misc       0.73      0.67      0.70       259\n",
      "      talk.religion.misc       0.69      0.51      0.58       236\n",
      "\n",
      "                accuracy                           0.87      5000\n",
      "               macro avg       0.87      0.87      0.87      5000\n",
      "            weighted avg       0.87      0.87      0.87      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_dataset,Y_train)\n",
    "Y_test_pred = clf.predict(X_test_dataset)\n",
    "sklearn_score_train = clf.score(X_train_dataset,Y_train)\n",
    "print(\"Sklearn's score on training data :\",sklearn_score_train)\n",
    "sklearn_score_test = clf.score(X_test_dataset,Y_test)\n",
    "print(\"Sklearn's score on testing data :\",sklearn_score_test)\n",
    "print(\"Classification report for testing data :-\")\n",
    "print(classification_report(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayes:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # count is a dictionary which stores several dictionaries corresponding to each news category\n",
    "        # each value in the subdictionary represents the freq of the key corresponding to that news category \n",
    "        self.count = {}\n",
    "        # classes represents the different news categories\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self,X_train,Y_train):\n",
    "        # This can take some time to complete       \n",
    "        self.classes = set(Y_train)\n",
    "        for class_ in self.classes:\n",
    "            self.count[class_] = {}\n",
    "            for i in range(len(X_train[0])):\n",
    "                self.count[class_][i] = 0\n",
    "            self.count[class_]['total'] = 0\n",
    "            self.count[class_]['total_points'] = 0\n",
    "        self.count['total_points'] = len(X_train)\n",
    "        \n",
    "        for i in range(len(X_train)):\n",
    "            for j in range(len(X_train[0])):\n",
    "                self.count[Y_train[i]][j]+=X_train[i][j]\n",
    "                self.count[Y_train[i]]['total']+=X_train[i][j]\n",
    "            self.count[Y_train[i]]['total_points']+=1\n",
    "    \n",
    "    def __probability(self,test_point,class_):\n",
    "        \n",
    "        log_prob = np.log(self.count[class_]['total_points']) - np.log(self.count['total_points'])\n",
    "        total_words = len(test_point)\n",
    "        for i in range(len(test_point)):\n",
    "            current_word_prob = test_point[i]*(np.log(self.count[class_][i]+1)-np.log(self.count[class_]['total']+total_words))\n",
    "            log_prob += current_word_prob\n",
    "        \n",
    "        return log_prob\n",
    "    def __predictSinglePoint(self,test_point):\n",
    "        \n",
    "        best_class = None\n",
    "        best_prob = None\n",
    "        first_run = True\n",
    "        \n",
    "        for class_ in self.classes:\n",
    "            log_probability_current_class = self.__probability(test_point,class_)\n",
    "            if (first_run) or (log_probability_current_class > best_prob) :\n",
    "                best_class = class_\n",
    "                best_prob = log_probability_current_class\n",
    "                first_run = False\n",
    "                \n",
    "        return best_class\n",
    "        \n",
    "  \n",
    "    def predict(self,X_test):\n",
    "        # This can take some time to complete\n",
    "        Y_pred = [] \n",
    "        for i in range(len(X_test)):\n",
    "        # print(i) # Uncomment to see progress\n",
    "            Y_pred.append( self.__predictSinglePoint(X_test[i]) )\n",
    "        \n",
    "        return Y_pred\n",
    "    \n",
    "    def score(self,Y_pred,Y_true):\n",
    "        # returns the mean accuracy\n",
    "        count = 0\n",
    "        for i in range(len(Y_pred)):\n",
    "            if Y_pred[i] == Y_true[i]:\n",
    "                count+=1\n",
    "        return count/len(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our score on testing data : 0.8718\n",
      "Classification report for testing data :-\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.75      0.81      0.78       233\n",
      "           comp.graphics       0.80      0.83      0.81       253\n",
      " comp.os.ms-windows.misc       0.82      0.83      0.83       249\n",
      "comp.sys.ibm.pc.hardware       0.82      0.88      0.85       240\n",
      "   comp.sys.mac.hardware       0.88      0.93      0.90       236\n",
      "          comp.windows.x       0.92      0.86      0.89       240\n",
      "            misc.forsale       0.81      0.86      0.83       261\n",
      "               rec.autos       0.92      0.93      0.92       269\n",
      "         rec.motorcycles       0.93      0.97      0.95       284\n",
      "      rec.sport.baseball       0.99      0.97      0.98       248\n",
      "        rec.sport.hockey       0.98      0.98      0.98       231\n",
      "               sci.crypt       0.96      0.90      0.93       233\n",
      "         sci.electronics       0.89      0.87      0.88       244\n",
      "                 sci.med       0.95      0.91      0.93       256\n",
      "               sci.space       0.94      0.93      0.93       246\n",
      "  soc.religion.christian       0.94      0.98      0.96       252\n",
      "      talk.politics.guns       0.77      0.89      0.83       249\n",
      "   talk.politics.mideast       0.93      0.90      0.92       281\n",
      "      talk.politics.misc       0.73      0.67      0.70       259\n",
      "      talk.religion.misc       0.69      0.51      0.58       236\n",
      "\n",
      "                accuracy                           0.87      5000\n",
      "               macro avg       0.87      0.87      0.87      5000\n",
      "            weighted avg       0.87      0.87      0.87      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf2 = MultinomialNaiveBayes()\n",
    "clf2.fit(X_train_dataset,Y_train)\n",
    "Y_test_pred = clf2.predict(X_test_dataset)\n",
    "our_score_test = clf2.score(Y_test_pred,Y_test)  \n",
    "print(\"Our score on testing data :\",our_score_test)\n",
    "print(\"Classification report for testing data :-\")\n",
    "print(classification_report(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of our model on test data: 0.8718\n",
      "Score of inbuilt sklearn's MultinomialNB on the same data : 0.8718\n"
     ]
    }
   ],
   "source": [
    "print(\"Score of our model on test data:\",our_score_test)\n",
    "print(\"Score of inbuilt sklearn's MultinomialNB on the same data :\",sklearn_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
